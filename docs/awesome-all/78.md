# awesome-video-generation（视频生成研究资源汇总）

本页面汇总了视频生成领域最新、最实用的研究论文、工具和数据集，涵盖2024-2025年的技术突破和行业应用，帮助你快速掌握该领域的核心资源。

---

## 工具与产品

| 名称 | 组织 | 特色 | 链接 |
|------|------|------|------|
| Sora | OpenAI | 2025年升级版本，支持更长时长视频生成，结合GPT-4o实现更精准的文本理解 | [官网](https://openai.com/sora) |
| SkyReels-V2 | 昆仑万维 | 全球首个支持无限时长电影生成的开源模型，采用扩散强迫框架，影视级质量 | [项目](https://www.xhby.net/content/s6805b326e4b0e37860aecbe7.html) |
| Veo 3 | Google DeepMind | 支持60秒视频生成，自动添加音频、 camera运动和角色表情，基于Gemini大模型 | [介绍](https://www.noupe.com/essentials/best-image-to-video-ai-generators.html) |
| Flow | Google | 专为电影制作设计，整合Veo、Imagen和Gemini，支持多场景叙事和专业镜头控制 | [官网](https://www.indiatoday.in/technology/news/story/google-io-2025-flow-is-ai-video-generator-tuned-for-filmmaking-google-says-it-is-working-with-hollywood-2727871-2025-05-21) |
| Stable Video 4D 2.0 | StabilityAI | 支持高保真4D资产生成和新视角合成，采用3D注意力机制提升时空一致性 | [官网](https://stability.ai/news/stable-video-4d-20-new-upgrades-for-high-fidelity-novel-views-and-4d-generation-from-a-single-video) |
| Firefly Video Model | Adobe | 无缝整合Premiere Pro，支持文本/图像生成视频、扩展现有视频，擅长自然场景和VFX效果 | [介绍](https://fixthephoto.com/adobe-firefly-video.html) |
| AvatarFX | Character.AI | 将静态图片转化为可说话的动态角色，支持唇同步和表情变化，适用于虚拟偶像 | [官网](http://m.toutiao.com/group/7496384916322566694/?upstream_biz=doubao) |
| Gen-2 | RunwayML | 持续更新的多模态视频生成工具，支持文本、图像和视频输入的创意生成 | [官网](https://research.runwayml.com/gen2) |

---

## 核心论文

### 文本到视频生成
- **2025年**
  - **Aether**: 几何感知的统一世界建模，支持3D和4D场景生成 [[论文]](https://github.com/topics/4d-generation)
  - **SkyReels-V2**: 基于扩散强迫框架的无限时长视频生成 [[论文]](https://www.xhby.net/content/s6805b326e4b0e37860aecbe7.html)
  - **Video 4DGen**: 通过 mutual optimization 增强视频和4D生成 [[论文]](https://github.com/topics/4d-generation)

- **2024年**
  - **Vlogger**: 使用文本生成短视频 [[论文]](https://arxiv.org/pdf/2401.09414.pdf) [[代码]](https://github.com/Vchitect/Vlogger)
  - **PEEKABOO**: 探索式视频生成 [[论文]](https://arxiv.org/pdf/2312.07509) [[项目]](https://jinga-lala.github.io/projects/Peekaboo/)
  - **Animate Anyone**: 控制角色动画生成 [[论文]](https://arxiv.org/pdf/2311.17117.pdf) [[代码]](https://github.com/HumanAIGC/AnimateAnyone)

### 图像到视频生成
- **2025年**
  - **Free4D**: 无需调优的4D场景生成，具有时空一致性 [[论文]](https://github.com/topics/4d-generation)
  - **SteerX**: 几何引导的3D和4D场景生成 [[论文]](https://github.com/topics/4d-generation)

- **2024年**
  - **VideoBooth**: 基于图像提示的视频生成 [[论文]](https://arxiv.org/pdf/2312.00777) [[项目]](https://vchitect.github.io/VideoBooth-project/)
  - **PhysGen**: 物理驱动的视频生成 [[论文]](https://arxiv.org/pdf/2409.18964) [[项目]](https://stevenlsw.github.io/physgen/)

### 视频编辑与控制
- **2025年**
  - **DragAnything**: 物体运动控制 [[论文]](https://arxiv.org/pdf/2403.07420.pdf) [[项目]](https://weijiawu.github.io/draganything_page/)
  - **Stable Video 4D 2.0**: 改进的多视角视频扩散模型 [[论文]](https://stability.ai/news/stable-video-4d-20-new-upgrades-for-high-fidelity-novel-views-and-4d-generation-from-a-single-video)

- **2024年**
  - **Video-P2P**: 基于注意力的文本驱动视频编辑 [[论文]](https://arxiv.org/pdf/2303.04761) [[项目]](https://video-p2p.github.io/)
  - **DynVideo-E**: 结合动态场景进行视频编辑 [[论文]](https://arxiv.org/pdf/2310.10624) [[项目]](https://showlab.github.io/DynVideo-E/)

### 视频理解与分析
- **2025年**
  - **ViCaS**: 结合整体和像素级视频理解的数据集与模型 [[论文]](https://github.com/Ali2500/ViCaS)
  - **SkyCaptioner-V1**: 影视级视频理解模型，提升提示词遵循能力 [[论文]](https://www.xhby.net/content/s6805b326e4b0e37860aecbe7.html)

---

## 数据集

- **ViCaS (2025)**: 包含20,416个视频，带有详细字幕和像素级分割掩码，用于视频字幕生成和语言引导的视频实例分割 [[论文]](https://github.com/Ali2500/ViCaS) [[数据集]](https://github.com/Ali2500/ViCaS)
- **UCF101**: 经典动作视频数据集，包含101类人类动作，13,320个视频剪辑 [[论文]](https://arxiv.org/pdf/1212.0402.pdf) [[数据集]](https://www.crcv.ucf.edu/data/UCF101.php)
- **DAVIS**: 视频目标分割数据集，包含50个视频序列，用于评估视频分割算法 [[论文]](https://arxiv.org/pdf/1704.00675.pdf) [[数据集]](https://davischallenge.org/)
- **WebVid-10M**: 大规模视频-文本对齐数据集，包含1000万个视频片段及对应文本描述 [[论文]](https://arxiv.org/pdf/2104.00650.pdf) [[数据集]](https://maxbain.com/webvid-dataset/)

---

## 评估指标

- **FVD (Frechet Video Distance)**: 评估生成视频的整体质量和真实性，基于视频特征的分布距离 [[论文]](https://openreview.net/pdf?id=rylgEULtdN) [[代码]](https://github.com/google-research/google-research/blob/master/frechet_video_distance/frechet_video_distance.py)
- **VMBench (2025)**: 首个感知对齐的视频运动评估基准，涵盖969种运动类型，从人类感知角度评估运动质量 [[论文]](https://arxiv.org/pdf/2503.10076v2)
- **MJ-Bench-Video (2025)**: 大规模视频偏好基准，从对齐性、安全性、精细度、连贯性和公平性五个维度评估视频生成 [[论文]](https://arxiv.org/pdf/2502.01719v3)
- **FV4D (2025)**: 专门用于评估4D生成模型的一致性指标 [[论文]](https://stability.ai/news/stable-video-4d-20-new-upgrades-for-high-fidelity-novel-views-and-4d-generation-from-a-single-video)

---

## 应用场景

- **影视制作**: Google Flow已被好莱坞电影人用于前期可视化和场景创作，支持多镜头连贯叙事
- **广告与营销**: Adobe Firefly Video Model可快速生成产品展示视频，支持自然场景和VFX效果
- **虚拟偶像**: Character.AI的AvatarFX可将静态图片转化为能说话、有表情的虚拟角色，应用于直播和互动娱乐
- **内容创作**: SkyReels-V2支持无限时长视频生成，适用于故事叙述、教育内容制作和创意视频生成
- **游戏开发**: Stable Video 4D 2.0可生成动态4D资产，用于游戏角色动画和场景构建

---

## 常见问题

### 如何选择合适的视频生成工具？
- 追求长视频生成: 选择SkyReels-V2（支持无限时长）
- 专业影视制作: 考虑Google Flow（与好莱坞合作优化）
- 与Adobe工作流整合: 优先Adobe Firefly Video Model
- 开源研究使用: Stable Video 4D 2.0提供免费商用许可
- 虚拟角色动画: Character.AI的AvatarFX专门优化人物动态

### 论文按什么顺序组织？
- 按会议级别和发表时间排序:
  1. CVPR
  2. ICCV
  3. ECCV
  4. NeurIPS
  5. ICLR
  6. AAAI
  7. arXiv预印本
  8. 其他期刊和会议

### 不同评估指标有什么区别？
- FVD: 评估整体视频质量和真实性，适用于基础质量检测
- VMBench: 专注于运动质量评估，适合需要流畅动作的场景
- MJ-Bench-Video: 从多维度评估生成视频与人类偏好的对齐程度
- FV4D: 专门用于4D生成模型的时空一致性评估

### 视频生成技术的主要挑战是什么？
- 长视频生成中的一致性保持
- 物理运动的合理性和自然性
- 复杂场景中多主体的互动处理
- 精确遵循文本指令，减少内容幻觉
- 提升生成速度同时保持高分辨率
